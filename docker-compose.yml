name: amor

services:
  # Single entrypoint for environments that only expose one port.
  # Provides / -> app, /grafana -> grafana, /prometheus -> prometheus.
  gateway:
    image: nginx:alpine
    ports:
      - "8000:80"
    volumes:
      - ./nginx/gateway.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - app
      - grafana
      - prometheus
    networks:
      - docprocessor-network

  # Main application
  app:
    build: .
    # NOTE: The app is exposed via the `gateway` service on port 8000.
    # If you want direct access as well, add a port mapping like "8001:8000".
    environment:
      # Service
      - SERVICE_NAME=document-processor
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO

      # Kafka
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC=documents

      # Redis
      - REDIS_HOST=redis
      - REDIS_PORT=6379

      # PostgreSQL
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DATABASE=docdb
      - POSTGRES_USER=docuser
      - POSTGRES_PASSWORD=docpass123

      # MongoDB
      - MONGO_HOST=mongo
      - MONGO_PORT=27017
      - MONGO_DATABASE=documents

      # API Keys (set these via .env file)
      - GOOGLE_TRANSLATE_API_KEY=${GOOGLE_TRANSLATE_API_KEY}
      - AZURE_TRANSLATOR_KEY=${AZURE_TRANSLATOR_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}

      # Ollama Local AI
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=qwen2.5:7b
      - OLLAMA_AUTO_PULL=true

      # NLLB Translation Model
      - NLLB_MODEL_PATH=/models/nllb-200-distilled-600M-ct2
      - NLLB_DEVICE=cuda
      - NLLB_COMPUTE_TYPE=int8_float16

      # FastText Language Detection
      - FASTTEXT_MODEL_PATH=/models/lid.176.bin

      # LanceDB Vector Store
      - LANCEDB_PATH=/data/vectors

    depends_on:
      ollama:
        condition: service_healthy
      kafka:
        condition: service_started
      redis:
        condition: service_started
      postgres:
        condition: service_started
      mongo:
        condition: service_started

    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    volumes:
      - ./data:/data/documents
      - ./models:/models:ro
      - lancedb-data:/data/vectors

    networks:
      - docprocessor-network

  # Apache Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - docprocessor-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    networks:
      - docprocessor-network

  # Redis
  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    networks:
      - docprocessor-network

  # PostgreSQL
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_DB: docdb
      POSTGRES_USER: docuser
      POSTGRES_PASSWORD: docpass123
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks:
      - docprocessor-network

  # MongoDB
  mongo:
    image: mongo:7
    ports:
      - "27017:27017"
    volumes:
      - mongo-data:/data/db
    networks:
      - docprocessor-network

  # Ollama Local AI Service
  ollama:
    image: ollama/ollama:latest
    container_name: amor-ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_KEEP_ALIVE=5m
      - OLLAMA_MAX_LOADED_MODELS=1
      - OLLAMA_NUM_PARALLEL=2
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ollama-data:/root/.ollama
    deploy:
      resources:
        limits:
          memory: 8G
    healthcheck:
      test: ["CMD-SHELL", "ollama list || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - docprocessor-network

  # Prometheus
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9091:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./monitoring/prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.route-prefix=/prometheus'
      - '--web.external-url=/prometheus'
      - '--web.enable-lifecycle'
    networks:
      - docprocessor-network

  # Grafana
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_SERVER_ROOT_URL=%(protocol)s://%(domain)s:8000/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH=/var/lib/grafana/dashboards/crawl-translation-dashboard.json
    volumes:
      - grafana-data:/var/lib/grafana
      - ./monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus
    networks:
      - docprocessor-network

volumes:
  postgres-data:
  mongo-data:
  prometheus-data:
  grafana-data:
  ollama-data:
  lancedb-data:

networks:
  docprocessor-network:
    driver: bridge
